{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import dirichlet, multinomial\n",
    "\n",
    "# Define the model parameters\n",
    "K = 3  # Number of populations\n",
    "L = 5  # Number of loci\n",
    "J = 5  # Number of alleles per locus\n",
    "\n",
    "# Define the prior distributions\n",
    "alpha = np.ones(J)  # Dirichlet prior parameter for allele frequencies\n",
    "\n",
    "# Define the data\n",
    "X = np.array([[1, 2, 3, 4, 5],\n",
    "             [1, 2, 3, 4, 5],\n",
    "             [1, 2, 3, 4, 5]])  # Genotype data\n",
    "\n",
    "# Initialize the MCMC chain\n",
    "Z = np.zeros(X.shape[0], dtype=int)  # Population assignments\n",
    "P = np.zeros((K, L, J))  # Allele frequencies\n",
    "\n",
    "# Sample population assignments, as a initial starting point assuming a uniform distr\n",
    "for j in range(X.shape[0]):\n",
    "    Z[j] = np.random.multinomial(1, np.ones(K) / K).argmax()\n",
    "\n",
    "indexes_dict = get_indexes_of_population(Z)\n",
    "\n",
    "for pop in range(Z.shape[1]):\n",
    "    pop_samples = X[indexes_dict[pop]]\n",
    "    for locus in range(X.shape[1]):\n",
    "        values,prior = get_vals_and_alpha_prior(pop_samples)\n",
    "        # Sample allele freqs from dirichlet prior from loci\n",
    "        # Save allele in nonhomogeneous list of allele freqs\n",
    "            # Make homogeneous matrix adding zeroes to nonexistent alleles\n",
    "            # Shape is: K, L, #highest number of alleles in any loci\n",
    "        # Make complete matrix of nonhomo list of allele freqs,\n",
    "\n",
    "# Implement Z assignation from new allele freq matrix\n",
    "\n",
    "# Run the MCMC chain\n",
    "for i in range(1000):\n",
    "\n",
    "    ## Given de pop assignments modify the alpha prior adding\n",
    "\n",
    "\n",
    "\n",
    "    # Sample allele frequencies\n",
    "    for k in range(K):\n",
    "        for l in range(L):\n",
    "            P[k, l, :] = np.random.dirichlet(alpha)\n",
    "\n",
    "    # Update allele frequencies based on population assignments\n",
    "    for j in range(X.shape[0]):\n",
    "        for l in range(L):\n",
    "            print(Z[j], l, X[j, l])\n",
    "            P[Z[j], l, X[j, l]] += 1\n",
    "\n",
    "# Normalize allele frequencies\n",
    "for k in range(K):\n",
    "    for l in range(L):\n",
    "        P[k, l, :] /= np.sum(P[k, l, :])\n",
    "\n",
    "# Print the results\n",
    "print(\"Population assignments:\", Z)\n",
    "print(\"Allele frequencies:\", P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[28 69]\n",
      "  [10 38]\n",
      "  [63 75]\n",
      "  [26 40]\n",
      "  [27 34]]\n",
      "\n",
      " [[48 35]\n",
      "  [50 51]\n",
      "  [59 46]\n",
      "  [37 58]\n",
      "  [86 86]]\n",
      "\n",
      " [[ 2 85]\n",
      "  [59 55]\n",
      "  [61 36]\n",
      "  [71 65]\n",
      "  [64 37]]\n",
      "\n",
      " [[24 31]\n",
      "  [99 56]\n",
      "  [56 98]\n",
      "  [83 91]\n",
      "  [93 32]]]\n",
      "[[10 38]\n",
      " [50 51]\n",
      " [59 55]\n",
      " [99 56]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "test_data = np.random.randint(0,100,(4,5,2))\n",
    "test_data\n",
    "print(test_data)\n",
    "print(test_data[:,1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,) [1 2 0 2]\n",
      "0\n",
      "[2]\n",
      "1\n",
      "[0]\n",
      "2\n",
      "[1, 3]\n",
      "{0: {1.0: 2.2549199497391548e-12, 2.0: 0.5498784079960031, 3.0: 0.03224026221398752, 4.0: 0.001350643652609562, 5.0: 0.000964228391025687, 6.0: 0.0018052828575614085, 7.0: 5.853067496582071e-07, 8.0: 0.15722290896881433, 9.0: 8.594073921151104e-07, 10.0: 0.2565368212036017}, 1: {1.0: 0.032932394783837554, 2.0: 1.4797749665306442e-12, 3.0: 0.9543320850323141, 4.0: 1.281436309562029e-05, 5.0: 3.2226849262518485e-06, 6.0: 0.0011357444030866293, 7.0: 0.0002869330189201512, 8.0: 2.962956658915021e-06, 9.0: 3.0900326109308247e-13, 10.0: 0.011293842755372027}, 2: {1.0: 8.469512897005319e-08, 2.0: 2.790096688519279e-06, 3.0: 0.0033300703207478125, 4.0: 0.2410100727729683, 5.0: 0.48714145424586663, 6.0: 9.403139477031956e-06, 7.0: 0.031208395437879122, 8.0: 1.8307119626453428e-06, 9.0: 2.470645519083048e-07, 10.0: 0.23729565151472928}, 3: {1.0: 0.02879983095792928, 2.0: 2.1250010985197525e-05, 3.0: 7.567784330673003e-08, 4.0: 0.035920148837891436, 5.0: 2.1790565967858116e-06, 6.0: 0.002274347504040388, 7.0: 0.3473572714540324, 8.0: 0.49795754037390155, 9.0: 0.03695863300917261, 10.0: 0.050708723117607185}, 4: {1.0: 0.003749704759152666, 2.0: 7.857969751379471e-21, 3.0: 0.00032647537041222694, 4.0: 0.01587875899379872, 5.0: 0.018736123586878418, 6.0: 0.008183581206311843, 7.0: 5.882260471750037e-05, 8.0: 0.003576280327859654, 9.0: 0.9494902531437746, 10.0: 7.094346620515401e-12}}\n",
      "{0: {1.0: 0.8729443428620988, 2.0: 0.08822460489472589, 3.0: 0.02024601041589599, 4.0: 5.41568297830856e-09, 5.0: 0.007463925522658314, 6.0: 0.010213524921629618, 7.0: 2.5129896185967948e-05, 8.0: 0.0006980335769395177, 9.0: 2.8102185463350846e-05, 10.0: 0.0001563203087198761}, 1: {1.0: 0.005589301217219924, 2.0: 0.13044778669392126, 3.0: 0.37365264540792964, 4.0: 0.0007713513945753403, 5.0: 0.00024733640369693717, 6.0: 0.48893778330178705, 7.0: 0.00021051296910035164, 8.0: 3.9743780041546325e-05, 9.0: 8.344710845881592e-05, 10.0: 2.0091723269125467e-05}, 2: {1.0: 2.6283692058481477e-09, 2.0: 0.18260349212957203, 3.0: 4.254225242587952e-11, 4.0: 0.807991548207046, 5.0: 9.013020422291671e-05, 6.0: 0.00853902897732384, 7.0: 0.0007040796941831248, 8.0: 3.1245366852739304e-05, 9.0: 9.265307753753222e-14, 10.0: 4.047274979518141e-05}, 3: {1.0: 0.0001133184905949426, 2.0: 9.386710466576899e-09, 3.0: 0.0049124877128613334, 4.0: 0.00015206260969644018, 5.0: 2.618071672065877e-05, 6.0: 0.09579802925320535, 7.0: 0.8838618077616663, 8.0: 0.009001078410931939, 9.0: 0.0061350256576126905, 10.0: 3.8638565013337725e-17}, 4: {1.0: 4.067385731687445e-11, 2.0: 2.2216134439650403e-05, 3.0: 1.9968333920367573e-09, 4.0: 4.2878046104379165e-09, 5.0: 0.0006329204287618838, 6.0: 0.001009153566918992, 7.0: 9.310226638636165e-07, 8.0: 5.785546997281252e-07, 9.0: 0.9983341348012049, 10.0: 5.916599900627297e-08}}\n",
      "{0: {1.0: 0.18977213553003836, 2.0: 0.6308828567318195, 3.0: 5.0364333494783e-07, 4.0: 0.00010892337786639178, 5.0: 5.720975775241719e-11, 6.0: 0.1573122143996358, 7.0: 0.0005897476764835036, 8.0: 0.02133361828239304, 9.0: 3.012187275141471e-10, 10.0: 1.0512439407372857e-35}, 1: {1.0: 8.592689802815922e-05, 2.0: 6.545575961300218e-05, 3.0: 0.9094147792585232, 4.0: 0.05295881548696547, 5.0: 7.033464360350017e-19, 6.0: 0.00022495465759882416, 7.0: 3.604729472621586e-05, 8.0: 0.032268053831401626, 9.0: 0.003121016452499148, 10.0: 0.0018249503606442904}, 2: {1.0: 0.08158612486670208, 2.0: 0.001747095137436319, 3.0: 2.1778211734797856e-13, 4.0: 0.2708281396634285, 5.0: 0.6034959514481797, 6.0: 0.03905078996290922, 7.0: 3.683168238444284e-14, 8.0: 1.326806230292553e-07, 9.0: 0.0032917659539107936, 10.0: 2.8655572952128405e-10}, 3: {1.0: 8.348281316739911e-05, 2.0: 5.420616542230298e-05, 3.0: 2.8789172633569144e-05, 4.0: 4.4310358250417214e-05, 5.0: 0.07198422737874913, 6.0: 0.005778311543763126, 7.0: 0.7426593374823395, 8.0: 0.16349248494483565, 9.0: 7.200793062638755e-12, 10.0: 0.015874850133638124}, 4: {1.0: 4.949779203346135e-11, 2.0: 0.002747909350036434, 3.0: 1.6955244659033761e-06, 4.0: 0.27221602525925603, 5.0: 0.0004977635440723901, 6.0: 4.759971593084394e-08, 7.0: 4.544440341731447e-05, 8.0: 4.0455597242345275e-07, 9.0: 0.6384250661869186, 10.0: 0.08606564352664717}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 2])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import dirichlet, multinomial\n",
    "\n",
    "\n",
    "## Define functions\n",
    "def get_vals_and_alpha_prior(data_mat):\n",
    "    summary = np.unique(data_mat, return_counts = True)\n",
    "    vals = summary[0]\n",
    "    prior = summary[1] + 1/len(vals) ## Definition of prior in original paper?, counts + some alpha that always sums to 1\n",
    "\n",
    "    return vals,prior\n",
    "\n",
    "\n",
    "def get_vals_and_alpha_prior_full_alleles(data_mat,data_general):\n",
    "    summary_locus_all_samples = np.unique(data_general) \n",
    "    summary_locus_pop = np.unique(data_mat, return_counts = True)\n",
    "    \n",
    "    # Create new column for unique values to save the population counts\n",
    "    to_concatenate = np.zeros(summary_locus_all_samples.shape[0])\n",
    "    summary_locus_all_samples = np.column_stack((summary_locus_all_samples, to_concatenate))\n",
    "\n",
    "    if summary_locus_pop[0].shape[0] > 0: # If population wasnt sampled, no alleles would be found, this tests if this array is not empty\n",
    "        # Add to the previous column the appropiate number of allele counts per locus per population\n",
    "        for allele in range(summary_locus_all_samples.shape[0]):\n",
    "            if summary_locus_all_samples[allele,0] in summary_locus_pop[0]:\n",
    "                pop_allele_index = np.where(summary_locus_pop[0] == summary_locus_all_samples[allele,0])\n",
    "\n",
    "                summary_locus_all_samples[allele,1] = summary_locus_pop[1][pop_allele_index[0][0]]\n",
    "\n",
    "    # Generate values and prior\n",
    "    vals = summary_locus_all_samples[:,0]\n",
    "    prior = summary_locus_all_samples[:,1] + 1/len(vals) ## Definition of prior in original paper?, counts + some alpha that always sums to 1\n",
    "\n",
    "    return vals,prior\n",
    "\n",
    "# Create dictionary to find the index (samples) assignated to a population\n",
    "def get_indexes_of_population(arr):\n",
    "    unique_values = np.unique(arr)\n",
    "    indexes_dict = {}\n",
    "    for value in unique_values:\n",
    "        #print(np.where(arr == value))\n",
    "        indexes_dict[value] = list(np.where(arr == value)[0])\n",
    "    return indexes_dict\n",
    "\n",
    "# Sample population assignments, as a initial starting point assuming a uniform distr\n",
    "# Assure that all populations are sampled to not generate problems down the line. Just resample if any pop is missing\n",
    "def initial_pop_assignment(K,Z):\n",
    "    all_pops_sampled = False\n",
    "    while not(all_pops_sampled):\n",
    "        for j in range(X.shape[0]):\n",
    "            Z[j] = np.random.multinomial(1, np.ones(K) / K).argmax()\n",
    "        if not(False in np.isin([x for x in range(K)],Z)):\n",
    "            all_pops_sampled = True\n",
    "    return Z\n",
    "\n",
    "# Sample allele freqs on a per pooulation and per loci basis\n",
    "def sample_allele_freqs(X,K, indexes_dict):\n",
    "    # List that will save the dictionary- allele frequencies of the loci per population\n",
    "    freq_dict_per_pop = []\n",
    "    for pop in range(K):\n",
    "        print(pop)\n",
    "        print(indexes_dict[pop])\n",
    "        pop_samples = X[indexes_dict[pop]]\n",
    "        # Define population dictionary\n",
    "        pop_dict = {}\n",
    "        # Iterate over each loci within the population\n",
    "        for locus in range(X.shape[1]):\n",
    "            values,prior = get_vals_and_alpha_prior_full_alleles(pop_samples[:,locus,:],X)\n",
    "            \n",
    "            # Sample allele freqs from dirichlet prior from loci\n",
    "            sampled_allele_freqs_L = np.random.dirichlet(prior)\n",
    "\n",
    "            # Save allele freqs in population dictionary\n",
    "            allele_dict = {}\n",
    "            for value, freq in zip(values, sampled_allele_freqs_L):\n",
    "                allele_dict[value] = freq\n",
    "            pop_dict[locus] = allele_dict\n",
    "\n",
    "        # Save population dictionary in freq_dict_per_pop\n",
    "        freq_dict_per_pop.append(pop_dict)\n",
    "    return freq_dict_per_pop\n",
    "\n",
    "\n",
    "# Generate population assignment probabilites from estimated allele frequencies. \n",
    "# Estimate the \"probability\" of the full genotype of an individual in a population and ponder \n",
    "\n",
    "def generate_pop_probabilities(X, K, freq_dict_per_pop):\n",
    "    sample_probs = []\n",
    "    for sample in range(X.shape[0]):\n",
    "        likelihoods = []\n",
    "        for pop in range(K):\n",
    "            pop_dict = freq_dict_per_pop[pop]\n",
    "            product = 1\n",
    "            for locus in range(X.shape[1]):\n",
    "                genotype = X[sample,locus]\n",
    "                allele_0_freq = pop_dict[locus][genotype[0]]\n",
    "                allele_1_freq = pop_dict[locus][genotype[1]]\n",
    "                product *= allele_0_freq*allele_1_freq\n",
    "            likelihoods.append(product)\n",
    "        probs = np.array(likelihoods)/sum(likelihoods)\n",
    "        sample_probs.append(probs)\n",
    "    sample_probs = np.array(sample_probs)\n",
    "    return sample_probs\n",
    "\n",
    "\n",
    "# Assign population from population probabilities estimated before\n",
    "def assign_pop_from_probs(Z, K, X, sample_probs):\n",
    "    for sample in range(X.shape[0]):\n",
    "        Z[j] = np.random.multinomial(1, sample_probs[sample]).argmax()\n",
    "    return Z\n",
    "\n",
    "\n",
    "# Define the model parameters\n",
    "K = 3  # Number of populations\n",
    "L = 5  # Number of loci\n",
    "\n",
    "# Define the prior distributions\n",
    "#alpha = np.ones(J)  # Dirichlet prior parameter for allele frequencies\n",
    "\n",
    "# Define the data\n",
    "X = np.array([[[1, 1],\n",
    "  [3, 3],\n",
    "  [4, 4],\n",
    "  [7, 7],\n",
    "  [9, 9]],\n",
    " [[1, 2],\n",
    "  [3, 3],\n",
    "  [4, 6],\n",
    "  [7, 7],\n",
    "  [9, 9]],\n",
    " [[2, 2],\n",
    "  [3, 3],\n",
    "  [4, 5],\n",
    "  [8, 8],\n",
    "  [9, 9]],\n",
    " [[2, 2],\n",
    "  [3, 3],\n",
    "  [4, 5],\n",
    "  [8, 7],\n",
    "  [9, 10]]])  # Genotype data\n",
    "\n",
    "# Initialize the MCMC chain\n",
    "Z = np.zeros(X.shape[0], dtype=int)  # Population assignments\n",
    "#P = np.zeros((K, L, J))  # Allele frequencies\n",
    "\n",
    "# Sample population assignments, as a initial starting point assuming a uniform distr\n",
    "Z = initial_pop_assignment(K,Z)\n",
    "\n",
    "\n",
    "indexes_dict = get_indexes_of_population(Z)\n",
    "\n",
    "print(Z.shape,Z)\n",
    "# Sample allele freqs on a per pooulation and per loci basis\n",
    "\n",
    "freq_dict_per_pop=sample_allele_freqs(X,K, indexes_dict)# Sample allele freqs on a per pooulation and per loci basis\n",
    "\n",
    "for pop in range(K):\n",
    "    print(freq_dict_per_pop[pop])\n",
    "\n",
    "# Implement Z assignation from new allele freq matrix\n",
    "\n",
    "sample_probs = generate_pop_probabilities(X, K, freq_dict_per_pop)\n",
    "Z = assign_pop_from_probs(Z, K, X, sample_probs)\n",
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import dirichlet, multinomial\n",
    "\n",
    "\n",
    "## Define functions\n",
    "\n",
    "def get_vals_and_alpha_prior_full_alleles(data_mat,data_general):\n",
    "    summary_locus_all_samples = np.unique(data_general) \n",
    "    summary_locus_pop = np.unique(data_mat, return_counts = True)\n",
    "    \n",
    "    # Create new column for unique values to save the population counts\n",
    "    to_concatenate = np.zeros(summary_locus_all_samples.shape[0])\n",
    "    summary_locus_all_samples = np.column_stack((summary_locus_all_samples, to_concatenate))\n",
    "\n",
    "    if summary_locus_pop[0].shape[0] > 0: # If population wasnt sampled, no alleles would be found, this tests if this array is not empty\n",
    "        # Add to the previous column the appropiate number of allele counts per locus per population\n",
    "        for allele in range(summary_locus_all_samples.shape[0]):\n",
    "            if summary_locus_all_samples[allele,0] in summary_locus_pop[0]:\n",
    "                pop_allele_index = np.where(summary_locus_pop[0] == summary_locus_all_samples[allele,0])\n",
    "\n",
    "                summary_locus_all_samples[allele,1] = summary_locus_pop[1][pop_allele_index[0][0]]\n",
    "\n",
    "    # Generate values and prior\n",
    "    vals = summary_locus_all_samples[:,0]\n",
    "    prior = summary_locus_all_samples[:,1] + 1/len(vals) ## Definition of prior in original paper?, counts + some alpha that always sums to 1\n",
    "\n",
    "    return vals,prior\n",
    "\n",
    "# Create dictionary to find the index (samples) assignated to a population\n",
    "def get_indexes_of_population(Z,K):\n",
    "    unique_values = np.unique(Z)\n",
    "    indexes_dict = {}\n",
    "    for pop in range(K):\n",
    "        #print(np.where(arr == value))\n",
    "        indexes_dict[pop] = list(np.where(Z == pop)[0])\n",
    "    return indexes_dict\n",
    "\n",
    "# Sample population assignments, as a initial starting point assuming a uniform distr\n",
    "# Assure that all populations are sampled to not generate problems down the line. Just resample if any pop is missing\n",
    "def initial_pop_assignment(K,Z):\n",
    "    all_pops_sampled = False\n",
    "    while not(all_pops_sampled):\n",
    "        for j in range(X.shape[0]):\n",
    "            Z[j] = np.random.multinomial(1, np.ones(K) / K).argmax()\n",
    "        if not(False in np.isin([x for x in range(K)],Z)):\n",
    "            all_pops_sampled = True\n",
    "    return Z\n",
    "\n",
    "# Sample allele freqs on a per pooulation and per loci basis\n",
    "def sample_allele_freqs(X,K, indexes_dict):\n",
    "    # List that will save the dictionary- allele frequencies of the loci per population\n",
    "    freq_dict_per_pop = []\n",
    "    for pop in range(K):\n",
    "        #print(pop)\n",
    "        #print(indexes_dict[pop])\n",
    "        pop_samples = X[indexes_dict[pop]]\n",
    "        # Define population dictionary\n",
    "        pop_dict = {}\n",
    "        # Iterate over each loci within the population\n",
    "        for locus in range(X.shape[1]):\n",
    "            values,prior = get_vals_and_alpha_prior_full_alleles(pop_samples[:,locus,:],X)\n",
    "            \n",
    "            # Sample allele freqs from dirichlet prior from loci\n",
    "            sampled_allele_freqs_L = np.random.dirichlet(prior)\n",
    "\n",
    "            # Save allele freqs in population dictionary\n",
    "            allele_dict = {}\n",
    "            for value, freq in zip(values, sampled_allele_freqs_L):\n",
    "                allele_dict[value] = freq\n",
    "            pop_dict[locus] = allele_dict\n",
    "\n",
    "        # Save population dictionary in freq_dict_per_pop\n",
    "        freq_dict_per_pop.append(pop_dict)\n",
    "    return freq_dict_per_pop\n",
    "\n",
    "\n",
    "# Generate population assignment probabilites from estimated allele frequencies. \n",
    "# Estimate the \"probability\" of the full genotype of an individual in a population and ponder \n",
    "\n",
    "def generate_pop_probabilities(X, K, freq_dict_per_pop):\n",
    "    sample_probs = []\n",
    "    for sample in range(X.shape[0]):\n",
    "        likelihoods = []\n",
    "        for pop in range(K):\n",
    "            pop_dict = freq_dict_per_pop[pop]\n",
    "            product = 1\n",
    "            for locus in range(X.shape[1]):\n",
    "                genotype = X[sample,locus]\n",
    "                allele_0_freq = pop_dict[locus][genotype[0]]\n",
    "                allele_1_freq = pop_dict[locus][genotype[1]]\n",
    "                product *= allele_0_freq*allele_1_freq\n",
    "            likelihoods.append(product)\n",
    "        probs = np.array(likelihoods)/sum(likelihoods)\n",
    "        print(\"-\",np.array(likelihoods),sum(likelihoods),probs)\n",
    "        sample_probs.append(probs)\n",
    "    sample_probs = np.array(sample_probs)\n",
    "    return sample_probs\n",
    "\n",
    "\n",
    "# Assign population from population probabilities estimated before\n",
    "def assign_pop_from_probs(Z, K, X, sample_probs):\n",
    "    for sample in range(X.shape[0]):\n",
    "        Z[sample] = np.random.multinomial(1, sample_probs[sample]).argmax()\n",
    "    return Z\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "# Define the model parameters\n",
    "K = 3  # Number of populations\n",
    "L = 5  # Number of loci\n",
    "\n",
    "# Define the data\n",
    "X = np.array([[[1, 1],\n",
    "  [3, 3],\n",
    "  [4, 4],\n",
    "  [7, 7],\n",
    "  [9, 9]],\n",
    " [[1, 2],\n",
    "  [3, 3],\n",
    "  [4, 6],\n",
    "  [7, 7],\n",
    "  [9, 9]],\n",
    " [[2, 2],\n",
    "  [3, 3],\n",
    "  [4, 5],\n",
    "  [8, 8],\n",
    "  [9, 9]],\n",
    " [[2, 2],\n",
    "  [3, 3],\n",
    "  [4, 5],\n",
    "  [8, 7],\n",
    "  [9, 10]]])  # Genotype data\n",
    "\n",
    "# Initialize the MCMC chain\n",
    "iterations = 1000\n",
    "\n",
    "Z_accum = []\n",
    "P_accum = []\n",
    "\n",
    "Z = np.zeros(X.shape[0], dtype=int)  # Population assignments\n",
    "# Sample population assignments, as a initial starting point assuming a uniform distr\n",
    "Z = initial_pop_assignment(K,Z)\n",
    "Z_accum.append(Z)\n",
    "\n",
    "# Run the MCMC chain\n",
    "\n",
    "for i in range(iterations):\n",
    "    # Get index from population\n",
    "\n",
    "    indexes_dict = get_indexes_of_population(Z,K)\n",
    "    print(\"Indexes\", indexes_dict)\n",
    "\n",
    "    # Sample allele freqs on a per pooulation and per loci basis\n",
    "\n",
    "    freq_dict_per_pop = sample_allele_freqs(X,K, indexes_dict)# Sample allele freqs on a per pooulation and per loci basis\n",
    "    P_accum.append(freq_dict_per_pop)\n",
    "\n",
    "    # Implement Z assignation from new allele freq matrix\n",
    "\n",
    "    sample_probs = generate_pop_probabilities(X, K, freq_dict_per_pop)\n",
    "    #print(sample_probs)\n",
    "    Z = assign_pop_from_probs(Z, K, X, sample_probs)\n",
    "    \n",
    "    print(Z)\n",
    "    for freqs in freq_dict_per_pop:\n",
    "        print(freqs)\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "\n",
    "print(Z_accum)\n",
    "print(P_accum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading file implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [3], 1: [0, 1, 2], 2: []}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_indexes_of_population_test(Z,K):\n",
    "    unique_values = np.unique(Z)\n",
    "    indexes_dict = {}\n",
    "    for pop in range(K):\n",
    "        #print(np.where(arr == value))\n",
    "        indexes_dict[pop] = list(np.where(Z == pop)[0])\n",
    "    return indexes_dict\n",
    "\n",
    "test_pop_ass = np.array([1,1,1,0])\n",
    "pops = 3\n",
    "get_indexes_of_population_test(test_pop_ass,pops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.unique(X[[]][:,4,:], return_counts = True)[0].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array = np.array([0,1,1,0])\n",
    "\n",
    "np.isin([0,1,2],test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[1 2 8 9]\n",
      "[[0. 0.]\n",
      " [1. 1.]\n",
      " [2. 1.]\n",
      " [3. 0.]\n",
      " [4. 0.]\n",
      " [5. 0.]\n",
      " [6. 0.]\n",
      " [7. 0.]\n",
      " [8. 1.]\n",
      " [9. 1.]]\n",
      "[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " array([0.1, 1.1, 1.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1.1, 1.1]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_vals_and_alpha_prior_full_alleles(data_mat,data_general):\n",
    "    summary_locus_all_samples = np.unique(data_general) \n",
    "    summary_locus_pop = np.unique(data_mat, return_counts = True)\n",
    "    \n",
    "    # Create new column for unique values to save the population counts\n",
    "    to_concatenate = np.zeros(summary_locus_all_samples.shape[0])\n",
    "    summary_locus_all_samples = np.column_stack((summary_locus_all_samples, to_concatenate))\n",
    "\n",
    "    # Add to the previous column the appropiate number of allele counts per locus per population\n",
    "    for allele in range(summary_locus_all_samples.shape[0]):\n",
    "        if summary_locus_all_samples[allele,0] in summary_locus_pop[0]:\n",
    "            pop_allele_index = np.where(summary_locus_pop[0] == summary_locus_all_samples[allele,0])\n",
    "\n",
    "            summary_locus_all_samples[allele,1] = summary_locus_pop[1][pop_allele_index[0][0]]\n",
    "\n",
    "    # Generate values and prior\n",
    "    vals = summary_locus_all_samples[:,0]\n",
    "    prior = summary_locus_all_samples[:,1] + 1/len(vals) ## Definition of prior in original paper?, counts + some alpha that always sums to 1\n",
    "\n",
    "    return vals,prior\n",
    "\n",
    "test_sample = np.arange(10)\n",
    "test_pop = np.array([1,2,8,9])\n",
    "\n",
    "print(test_sample)\n",
    "print(test_pop)\n",
    "\n",
    "get_vals_and_alpha_prior_test(test_pop,test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2]),)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.where(test_pop == 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,1])/sum([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[0,1],[2,3],[4,5]])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.33333333, 0.33333333])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(K) / K"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quarto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
